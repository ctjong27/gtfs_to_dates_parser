{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_path = \"./files/extracted/\"\n",
    "transfers_path = \"/transfers.txt\"\n",
    "gtfs_generation_dates = [item for item in os.listdir(extract_path) if os.path.isdir(os.path.join(extract_path, item))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_transfers_dates_file(gtfs_generation_date):\n",
    "    # Read the calendar_dates.txt file into a DataFrame\n",
    "    transfers = pd.read_csv(extract_path + gtfs_generation_date + transfers_path)\n",
    "\n",
    "    return(transfers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35532, 4)\n",
      "(0, 4)\n"
     ]
    }
   ],
   "source": [
    "total_transfers = pd.DataFrame()\n",
    "# Set the path to the GTFS files\n",
    "for gtfs_date in gtfs_generation_dates:\n",
    "    # calendar_file = folder_path + filename # example: calendar_20181221.txt'\n",
    "    total_transfers = pd.concat([total_transfers, process_transfers_dates_file(gtfs_date)])\n",
    "    \n",
    "print(total_transfers[total_transfers['transfer_type'] == 2].shape)\n",
    "print(total_transfers[total_transfers['transfer_type'] != 2].shape)\n",
    "\n",
    "# Retrieve unique calendar dates from aggregation of calendar_dates.txt\n",
    "total_transfers = total_transfers[['from_stop_id','to_stop_id']]\n",
    "transfers_df = total_transfers.drop_duplicates()\n",
    "transfers_df = transfers_df.sort_values(by=['from_stop_id', 'to_stop_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary to store the distinct stations and their corresponding stops\n",
    "stations = {}\n",
    "\n",
    "# loop through each row of the transfers dataframe\n",
    "for index, row in transfers_df.iterrows():\n",
    "    from_stop_id = row['from_stop_id']\n",
    "    to_stop_id = row['to_stop_id']\n",
    "    \n",
    "    # add from_stop_id to stations dictionary if it doesn't already exist\n",
    "    if from_stop_id not in stations:\n",
    "        stations[from_stop_id] = [from_stop_id]\n",
    "    \n",
    "    # add to_stop_id to the corresponding station in the stations dictionary if it doesn't already exist\n",
    "    if to_stop_id not in stations[from_stop_id]:\n",
    "        stations[from_stop_id].append(to_stop_id)\n",
    "    \n",
    "    # if to_stop_id already exists in stations dictionary, add any stops in the from_stop_id station to the to_stop_id station\n",
    "    for station, stops in stations.items():\n",
    "        if to_stop_id in stops and from_stop_id not in stops:\n",
    "            stops.append(from_stop_id)\n",
    "        elif from_stop_id in stops and to_stop_id not in stops:\n",
    "            stops.append(to_stop_id)\n",
    "\n",
    "# create a list to store the station and stop data\n",
    "station_stop_list = []\n",
    "\n",
    "# loop through the stations dictionary and add the data to the station_stop_list\n",
    "for station in stations:\n",
    "    station_stops = sorted(stations[station])\n",
    "    if not any(d['stop_id'] == station_stops for d in station_stop_list):\n",
    "        station_stop_list.append({'station_id': station, 'stop_id': station_stops})\n",
    "\n",
    "# create a pandas dataframe from the station_stop_list\n",
    "station_stop_df = pd.DataFrame(station_stop_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list to store the stop and station data\n",
    "stop_station_list = []\n",
    "\n",
    "# loop through the station_stop_df dataframe and add the data to the stop_station_list\n",
    "for index, row in station_stop_df.iterrows():\n",
    "    station = row['station_id']\n",
    "    stops = row['stop_id']\n",
    "    for stop in stops:\n",
    "        stop_station_list.append([stop, station])\n",
    "\n",
    "# create a pandas dataframe from the stop_station_list\n",
    "stop_station_df = pd.DataFrame(stop_station_list, columns=['stop_id', 'station_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a mappings folder if it doesn't exist\n",
    "if not os.path.exists('mappings'):\n",
    "    os.makedirs('mappings')\n",
    "\n",
    "# Generate a mapping file for future reference\n",
    "station_stop_df.to_csv('mappings/stations_to_stops.csv', index=False)\n",
    "\n",
    "# Generate a mapping file for future reference\n",
    "stop_station_df.to_csv('mappings/stops_to_stations.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8b887db99f8edfa7f3e3a008cc1b31fa63afeb09acb3c9f070418078094f7b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
